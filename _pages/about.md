---
permalink: /
title: "Hello, I'm Srihita"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---


I am a Postdoctoral Scholar at UC San Diego Psychology and work with Prof. Timothy Gentner in the Auditory Neuroscience Laboratory. My research aims at expanding my PhD work on understanding how predictive coding is implemented in songbird auditory neurons and how complex behaviors such as birdsong recognition can be explained using the predictive coding framework. More broadly, I am interested in computational modeling to explain perceptual inference of natural signals, especially temporally patterned signals such as speech and audio, and how these inferences are relevant to behavior. 
Before this, I graduated from IIT Madras with a BTech & MTech in Biotechnology. For my Masters thesis, I worked with Prof. Devarajan Karunagaran on role of microRNAs in breast cancer.

You can find out more in my resume and CV, or our [lab website](http://gentnerlab.ucsd.edu/).

Research
======

Decoding complex behaviors such as vocal recognition with predictive coding
------
Comprehension of vocal communication signals in both songbirds and humans is intricately tied to anticipations rooted in prior sensory knowledge. To elucidate the underlying perceptual and cognitive processes, the theoretical framework of predictive coding proves invaluable. Beyond elucidating general perception, this framework extends its explanatory power to complex behavioral phenomena, including the intricate process of recognizing vocal sequences. An intriguing question arises: is the internal model adaptable based on complex behavior?  The neural and cognitive mechanisms underlying this are not well understood. Employing innovative methods for analyzing both the acoustic and temporal dimensions of vocal signals, we subsequently embark on a dual approach—examining the behavioral and physiological dimensions—to unravel the foundations of the predictive structure inherent in birdsong.

In our experimental paradigm, songbirds underwent training in a song recognition decision-making task, presented with entire song repertoires. Notably, our findings indicate that songbirds exhibit proficient performance in recognizing random segments of birdsong, suggesting that they learned the underlying song model of the trained repertoires. Furthermore, they recognize song segments even when the temporal structure of the song is disrupted, underscoring the resilience of their learned song models to temporal alterations. Using the same behavioral framework, we then recorded from populations of sensory neurons while birds were making perceptual decisions to understand whether and to elucidate in which ways complex behaviors bias this internal model for perception in songbirds. We are studying if vocal recognition can by explained by predictive coding when the generative model matches the stimulus in the world? We hypothesize can explain vocal recognition as when the song model matches the exterior signal or equivalent to when the prediction error goes to zero. 

Predictive coding for natural vocal signals in the songbird auditory forebrain
------
Predictive coding posits that incoming sensory signals are compared to an internal generative model with resulting error signals carried in the responses of single neurons. Empirical support for predictive coding in individual neurons, particularly in the auditory system and for natural stimuli, has proven difficult to observe. Here, we developed a neural network that uses current sensory context to predict future spectral-temporal features in a natural communication signal, birdsong. Using this model, we represent the waveform of any birdsong as either a set of weighted “latent” predictive features evolving in time, or a corresponding error representation that reflects the difference between the predicted and actual song. We then recorded responses of single neurons in caudomedial nidopallium (NCM), caudal mesopallium (CMM) and Field L, analogs of mammalian auditory cortex, in anesthetized European starlings listening to conspecific songs, and computed the linear/non-linear receptive fields for each neuron fit separately to the spectro-temporal, predictive, and error representations of song. Comparisons between the quality of each receptive field model reveal that NCM spiking responses are best modeled by the predictive spectrotemporal features of song, while CMM and Field L responses capture both predictive and error features. Neural activity is selective for carrying information explicitly about prediction and prediction errors, and their preferences vary across the auditory forebrain. We conclude that this provides strong support for the notion that individual neurons in songbirds encode information related to multiple stimulus representations guided by predictive coding simultaneously.





